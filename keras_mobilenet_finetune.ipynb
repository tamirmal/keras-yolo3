{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamirmal/keras-yolo3/blob/master/keras_mobilenet_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lqVqFAHwexdb",
        "colab_type": "code",
        "outputId": "eed6626a-329c-4dcc-dc5f-e03a8b7f0da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OXJhBC5_fPPe",
        "colab_type": "code",
        "outputId": "e3a0350a-8d47-46c1-c358-e0c6d6ce8d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "!pip install keras_applications\n",
        "!pip install ipdb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.6/dist-packages (1.0.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.11.0)\n",
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/80/fe/4564de08f174f3846364b3add8426d14cebee228f741c27e702b2877e85b/ipdb-0.11.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (40.6.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (4.3.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (4.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (4.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (1.0.15)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.0.0->ipdb) (1.11.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.0.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipdb) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipdb) (0.1.7)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Running setup.py bdist_wheel for ipdb ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a8/0e/e2/ffc7bedd430bfd12e9dba3c4dd88906bc42962face85bc4df7\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e5t8cYdMfhq1",
        "colab_type": "code",
        "outputId": "2f600477-e450-46e5-a2a0-cc92e0fc14f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11084
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "import os.path\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "classes_list = []\n",
        "\n",
        "network_input_shape = {\n",
        "    'vgg16': (224, 224),\n",
        "    'mobilenet2': (224, 224),\n",
        "    'mobilenet1': (224, 224),\n",
        "}\n",
        "\n",
        "\n",
        "def process_lines(lines, type):\n",
        "    \"\"\"\n",
        "    lines shape\n",
        "    /home/tamirmal/workspace/git/tau_proj_prep/TRAIN/IMG_20181226_180908_HHT.jpg 921,1663,1646,2282,0 2066,1459,2698,2002,0 2866,1067,3695,1664,0\n",
        "    /home/tamirmal/workspace/git/tau_proj_prep/TRAIN/IMG_20181227_001359_HHT.jpg 1717,1431,2721,2151,0\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    y = []\n",
        "\n",
        "    visualize = False\n",
        "\n",
        "    for line in lines:\n",
        "        img_path = line.split()[0]\n",
        "        try:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/Colab Notebooks/'+img_path)\n",
        "            if img is None:\n",
        "                print(\"Falied to open {}\".format(img_path))\n",
        "                continue\n",
        "        except:\n",
        "            print(\"Falied to open {}\".format(img_path))\n",
        "            continue\n",
        "\n",
        "        for box in line.split()[1:]:\n",
        "            tokens = box.split(',')\n",
        "            tokens = [int(t) for t in tokens]\n",
        "            x1, y1, x2, y2 = tokens[0:4]\n",
        "            gt = tokens[4]\n",
        "            # need to make the image \"square\", because it will be reshaped later & we want to maintain the aspect ratio\n",
        "            h = y2 - y1\n",
        "            w = x2 - x1\n",
        "            d = max(h, w)\n",
        "            x1, y1, x2, y2 = x1, y1, x1 + d, y1 + d\n",
        "            # crop : left, upper, right, lower\n",
        "            copy_im = img.copy()\n",
        "            cropped = copy_im.crop((x1, y1, x2, y2))\n",
        "            cropped = cropped.resize(network_input_shape[type])\n",
        "            sample = image.img_to_array(cropped)\n",
        "            #sample = np.expand_dims(sample, axis=0)\n",
        "\n",
        "            data.append(sample)\n",
        "            y.append(gt)\n",
        "\n",
        "            # Count how much classes we have\n",
        "            if gt not in classes_list:\n",
        "                classes_list.append(gt)\n",
        "\n",
        "            ########## DEBUG HOOKS ############\n",
        "            if visualize:\n",
        "                from matplotlib import pyplot\n",
        "                pyplot.figure()\n",
        "                pyplot.imshow(cropped)\n",
        "                pyplot.show()\n",
        "            ###################################\n",
        "\n",
        "    data = np.array(data)\n",
        "    y = np.array(y)\n",
        "    return data, y\n",
        "# End\n",
        "\n",
        "\"\"\"\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "def inception_v3_get_model(num_classes):\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "    img_width, img_height = 299, 299  # Inception image size\n",
        "    top_layers_checkpoint_path = 'cp.top.best.hdf5'\n",
        "    fine_tuned_checkpoint_path = 'cp.fine_tuned.best.hdf5'\n",
        "    new_extended_inception_weights = 'final_weights.hdf5'\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    # and a logistic layer -- we have 2 classes\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(input=base_model.input, output=predictions)\n",
        "\n",
        "    assert 0  # TODO\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "from keras.applications import MobileNet\n",
        "def mobilenet_get_model(num_classes):\n",
        "    base_model = MobileNet(weights='imagenet', include_top=False)  # imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)  # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "    x = Dense(1024, activation='relu')(x)  # dense layer 2\n",
        "    x = Dense(512, activation='relu')(x)  # dense layer 3\n",
        "    preds = Dense(num_classes, activation='softmax')(x)  # final layer with softmax activation\n",
        "    model = Model(inputs=base_model.input, outputs=preds)\n",
        "\n",
        "    # freeze all layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    # or if we want to set the first 20 layers of the network to be non-trainable, rest are trainable\n",
        "    for layer in model.layers[20:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    print(\"Print model layers\")\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        print(i, layer.name)\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# End\n",
        "\"\"\"\n",
        "\n",
        "from keras.applications import MobileNetV2\n",
        "def mobilenet2_get_model(num_classes):\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    # freeze all layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    base_model.summary()\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# End\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "###################### MOBILENET ######################\n",
        "\"\"\"\n",
        "from keras.applications import mobilenet\n",
        "from keras.optimizers import Adam\n",
        "def mobilenet1_get_model(num_classes):\n",
        "  \n",
        "  base_model = mobilenet.MobileNet(include_top=False, weights='imagenet',\n",
        "                                   input_shape=(224,224,3))\n",
        "  print(\"base\")\n",
        "  base_model.summary()\n",
        "  \n",
        "  x = Sequential()\n",
        "  x.add(base_model)\n",
        "  x.add(GlobalAveragePooling2D())\n",
        "  x.add(Dropout(0.5))\n",
        "  x.add(Dense(512))\n",
        "  x.add(Dropout(0.5))\n",
        "  x.add(Dense(num_classes, activation = 'sigmoid'))\n",
        "  print(\"my additions\")\n",
        "  x.summary()\n",
        "  return x\n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "  base_model = mobilenet.MobileNet(weights='imagenet',\n",
        "                                     input_shape=(224,224,3), classes=num_classes) \n",
        "  base_model.compile(optimizer = Adam(lr = 1e-4), loss='categorical_crossentropy',\n",
        "                       metrics = ['accuracy', 'mae'])\n",
        "  base_model.summary()\n",
        "  return base_model\n",
        "  \"\"\"\n",
        "# End\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "def test_mobilenet1(model, train_gen, val_gen, dataset):\n",
        "  early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=3)\n",
        "  callbacks_list = [early]\n",
        "  \n",
        "  epochs = 100\n",
        "  batch_size = 32\n",
        "  train_data, train_y, val_data, val_y = dataset\n",
        "  steps_per_epoch = int(len(train_data)/batch_size)\n",
        "  #steps_per_epoch_val = int(len(val_data)/batch_size)\n",
        "  steps_per_epoch_val = steps_per_epoch\n",
        "  \n",
        "  print(\"len data {}, len val {}\".format(len(train_data), len(val_data)))\n",
        "  print(\"steps per epoch : {}, val : {}\".format(steps_per_epoch, steps_per_epoch_val))\n",
        "  \n",
        "  print(\"Freezing everything except last 5 layers\")\n",
        "  for layer in model.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  model.compile(optimizer = Adam(lr = 1e-4), loss='categorical_crossentropy',\n",
        "                       metrics = ['accuracy', 'mae'])\n",
        "  model.summary()\n",
        "  model.fit_generator(train_gen.flow(train_data, train_y, batch_size=batch_size),\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=epochs, initial_epoch=0,\n",
        "                    validation_data=val_gen.flow(val_data, val_y, batch_size=batch_size),\n",
        "                    validation_steps=steps_per_epoch_val)\n",
        "\n",
        "  print(\"unfreeze all model ...\")\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "  \n",
        "  model.compile(optimizer = Adam(lr = 1e-4), loss='categorical_crossentropy',\n",
        "                       metrics = ['accuracy', 'mae'])\n",
        "  model.summary()\n",
        "  model.fit_generator(train_gen.flow(train_data, train_y, batch_size=batch_size),\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=2*epochs, initial_epoch=epochs,\n",
        "                    validation_data=val_gen.flow(val_data, val_y, batch_size=batch_size),\n",
        "                    validation_steps=steps_per_epoch_val)\n",
        "   \n",
        "\n",
        "def prep_mobilenet(img_array):\n",
        "  processed_image_mobilenet = mobilenet.preprocess_input(img_array.copy())\n",
        "  return processed_image_mobilenet\n",
        "# End\n",
        "\"\"\"\n",
        "#######################################################\n",
        "\"\"\"\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.optimizers import SGD\n",
        "def vgg16_get_model(num_classes):\n",
        "    vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    # freeze all layers\n",
        "    for layer in vgg.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    vgg.summary()\n",
        "\n",
        "    print(\"Using base VGG as feature extractor\")\n",
        "    vgg_features = Model(inputs=vgg.input, outputs=vgg.output)\n",
        "\n",
        "    x = vgg.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    my_model = Model(inputs=vgg.input, outputs=x)\n",
        "    my_model.summary()\n",
        "\n",
        "    return my_model, vgg_features\n",
        "# End\n",
        "\n",
        "\n",
        "def train_post_classifier(lines, idxs_train, idxs_val, type='vgg16'):\n",
        "    # prepare data\n",
        "    train_data, y = process_lines(lines[idxs_train], type)\n",
        "    val_data, vy = process_lines(lines[idxs_val], type)\n",
        "\n",
        "    # prepare model\n",
        "    num_train = len(idxs_train)\n",
        "    num_val = len(idxs_val)\n",
        "    num_classes = len(classes_list)\n",
        "    top_epochs = 50\n",
        "\n",
        "    print(\"num classes {}\".format(num_classes))\n",
        "    train_y = to_categorical(y, num_classes)\n",
        "    val_y = to_categorical(vy, num_classes)\n",
        "\n",
        "\n",
        "    # Get model\n",
        "    if type == 'vgg16':\n",
        "        net, vgg_features = vgg16_get_model(num_classes)\n",
        "    elif type == 'mobilenet2':\n",
        "        net = mobilenet2_get_model(num_classes)\n",
        "    elif type == 'mobilenet1':\n",
        "        net = mobilenet1_get_model(num_classes)\n",
        "    else:\n",
        "        print(\"only vgg16 for now\")\n",
        "        assert 0\n",
        "\n",
        "    # Compile\n",
        "    if type == 'vgg16':\n",
        "        sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "        net.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    elif type == 'mobilenet2':\n",
        "        sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "        net.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n",
        "    elif type == 'mobilenet1':\n",
        "        print('mobilenet1 already complied')\n",
        "    else:\n",
        "        print(\"only vgg16 for now\")\n",
        "        assert 0\n",
        "\n",
        "    print(\"==============================================\")\n",
        "    print(\"===== Training CNNs\")\n",
        "    print(\"==============================================\")\n",
        "    # define input data generators\n",
        "    shift = 0.1\n",
        "    datagen_train = ImageDataGenerator(rotation_range=30, width_shift_range=shift, height_shift_range=shift,\n",
        "                                       horizontal_flip=True, zoom_range=0.2)\n",
        "    datagen_train.fit(train_data)\n",
        "\n",
        "    # For validation, do not rotate. do less augmentation\n",
        "    shift = 0.05\n",
        "    datagen_test = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift,\n",
        "                                       horizontal_flip=True, zoom_range=0.1)\n",
        "    datagen_test.fit(val_data)\n",
        "\n",
        "    test_mobilenet1(net, datagen_train, datagen_test, [train_data, train_y, val_data, val_y])    \n",
        "    \n",
        "    \"\"\"\n",
        "    print(\"==== Starting training - all layers but last are freezed ====\")\n",
        "    batch_size = 32\n",
        "    epochs = 50\n",
        "    steps_per_epoch = num_train/batch_size\n",
        "    steps_per_epoch_val = num_val/batch_size\n",
        "    net.fit_generator(datagen_train.flow(train_data, train_y, batch_size=batch_size),\n",
        "                      steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
        "                      validation_data=datagen_test.flow(val_data, val_y, batch_size=batch_size),\n",
        "                      validation_steps=steps_per_epoch_val)\n",
        "    net.save_weights('post_vgg16.h5')\n",
        "    print(\"============================= DONE CNN\")\n",
        "\n",
        "    print(\"==========================================\")\n",
        "    print(\"==== training SVM\")\n",
        "    print(\"==========================================\")\n",
        "    \n",
        "    def vgg_extract_features_img_array(img_array, model):\n",
        "      x = np.expand_dims(img_array, axis=0)\n",
        "      x = preprocess_input(x)\n",
        "      features = model.predict(x)\n",
        "      return features\n",
        "\n",
        "    \n",
        "    # define input data generators\n",
        "    shift = 0.1\n",
        "    datagen_train = ImageDataGenerator(rotation_range=30, width_shift_range=shift, height_shift_range=shift,\n",
        "                                       horizontal_flip=True, zoom_range=0.2)\n",
        "    datagen_train.fit(train_data)\n",
        "\n",
        "    # For validation, do not rotate. do less augmentation\n",
        "    shift = 0.05\n",
        "    datagen_test = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift,\n",
        "                                       horizontal_flip=True, zoom_range=0.1)\n",
        "    datagen_test.fit(val_data)\n",
        "\n",
        "    samples_train = 50*len(train_data)\n",
        "    svm_x_data = []\n",
        "    svm_y_data = []\n",
        "    cnt = 0\n",
        "    for x_batch, y_batch in datagen_train.flow(train_data, y, batch_size=1):\n",
        "        svm_x_data.append(vgg_extract_features_img_array(x_batch[0],vgg_features))\n",
        "        svm_y_data.append(y_batch[0])\n",
        "        cnt += 1\n",
        "        if cnt > samples_train:\n",
        "            break\n",
        "\n",
        "    svm_x_data = np.array(svm_x_data)\n",
        "    svm_y_data = np.array(svm_y_data)\n",
        "    svm_x_data = np.reshape(svm_x_data, (len(svm_x_data), -1))\n",
        "#    svm_y_data = np.reshape(svm_y_data, (len(svm_y_data), -1))\n",
        "    \n",
        "    param = [\n",
        "        {\n",
        "            \"kernel\": [\"linear\"],\n",
        "            \"C\": [1]\n",
        "        },\n",
        "        #        {\n",
        "        #            \"kernel\": [\"rbf\"],\n",
        "        #            \"C\": [1, 10, 100, 1000],\n",
        "        #            \"gamma\": [1e-2, 1e-3, 1e-4, 1e-5]\n",
        "        #        }\n",
        "    ]\n",
        "\n",
        "    # request probability estimation\n",
        "    svm = SVC(probability=True)\n",
        "    # 10-fold cross validation, use 4 thread as each fold and each parameter set can be train in parallel\n",
        "    clf = GridSearchCV(svm, param, cv=4, n_jobs=1, verbose=3)\n",
        "    #import ipdb; ipdb.set_trace()\n",
        "    clf.fit(svm_x_data, svm_y_data)\n",
        "    print(\"\\nBest parameters set:\")\n",
        "    print(clf.best_params_)\n",
        "    clf = clf.best_estimator_\n",
        "\n",
        "    print(\"Run on test set :\")\n",
        "    samples_val = 20*len(train_data)\n",
        "    val_svm_x_data = []\n",
        "    val_svm_y_data = []\n",
        "    cnt = 0\n",
        "    for x_batch, y_batch in datagen_train.flow(val_data, vy, batch_size=1):\n",
        "        val_svm_x_data.append(vgg_extract_features_img_array(x_batch[0],vgg_features))\n",
        "        val_svm_y_data.append(y_batch[0])\n",
        "        cnt += 1\n",
        "        if cnt > samples_val:\n",
        "            break\n",
        "\n",
        "    val_svm_x_data = np.array(val_svm_x_data)\n",
        "    val_svm_y_data = np.array(val_svm_y_data)\n",
        "    \n",
        "    val_svm_x_data = np.reshape(val_svm_x_data, (len(val_svm_x_data), -1))\n",
        "#    val_svm_y_data = np.reshape(val_svm_y_data, (len(val_svm_y_data), -1))\n",
        "    \n",
        "    y_predict = clf.predict(val_svm_x_data)\n",
        "\n",
        "    print(\"y predicted\")\n",
        "    print(y_predict)\n",
        "    print(\"val svm y data\")\n",
        "    print(val_svm_y_data)\n",
        "    print(\"\\nConfusion matrix:\")\n",
        "    #y_lables = val_svm_y_data.copy()\n",
        "    #labels = sorted(list(set(y_lables)))\n",
        "    #print(\"labels:\")\n",
        "    #print(\"Labels: {0}\\n\".format(\",\".join(labels)))\n",
        "    #print(labels)\n",
        "    #import ipdb; ipdb.set_trace()\n",
        "    #    print(confusion_matrix(val_svm_y_data, y_predict, labels=labels))\n",
        "    print(confusion_matrix(val_svm_y_data, y_predict))\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(val_svm_y_data, y_predict))\n",
        "\n",
        "    out_cls_path = '/content/drive/My Drive/Colab Notebooks/svm.dump'\n",
        "    joblib.dump(clf, out_cls_path)\n",
        "    \"\"\"\n",
        "\n",
        "    print('end')\n",
        "# End\n",
        "\n",
        "\n",
        "def main():\n",
        "    print('unit testing')\n",
        "    annotation_path = 'OUTyolo_train.txt'\n",
        "    with open('/content/drive/My Drive/Colab Notebooks/'+annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "        lines = np.array(lines)\n",
        "\n",
        "    val_split = 0.3\n",
        "    val_idx = int(val_split * len(lines))\n",
        "    train_idx = len(lines) - val_idx\n",
        "    idxs_train = [i for i in range(train_idx)]\n",
        "    idxs_val = [i for i in range(train_idx, len(lines))]\n",
        "    train_post_classifier(lines, idxs_train, idxs_val, type='mobilenet1')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unit testing\n",
            "num classes 4\n",
            "base\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 3,206,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "my additions\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,755,716\n",
            "Trainable params: 3,733,828\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "mobilenet1 already complied\n",
            "==============================================\n",
            "===== Training CNNs\n",
            "==============================================\n",
            "len data 78, len val 28\n",
            "steps per epoch : 2, val : 2\n",
            "Freezing everything except last 5 layers\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,755,716\n",
            "Trainable params: 526,852\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 6s 3s/step - loss: 1.8667 - acc: 0.1875 - mean_absolute_error: 0.5121 - val_loss: 1.6191 - val_acc: 0.3393 - val_mean_absolute_error: 0.4406\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 1.9465 - acc: 0.3051 - mean_absolute_error: 0.5621 - val_loss: 1.4965 - val_acc: 0.3393 - val_mean_absolute_error: 0.4794\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.3988 - acc: 0.1900 - mean_absolute_error: 0.5519 - val_loss: 1.3889 - val_acc: 0.3393 - val_mean_absolute_error: 0.5047\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 1.4357 - acc: 0.4062 - mean_absolute_error: 0.5817 - val_loss: 1.3466 - val_acc: 0.3393 - val_mean_absolute_error: 0.5371\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.4209 - acc: 0.3276 - mean_absolute_error: 0.6127 - val_loss: 1.3333 - val_acc: 0.2857 - val_mean_absolute_error: 0.5678\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.4807 - acc: 0.3094 - mean_absolute_error: 0.6143 - val_loss: 1.3224 - val_acc: 0.2857 - val_mean_absolute_error: 0.5859\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 486ms/step - loss: 1.3475 - acc: 0.3281 - mean_absolute_error: 0.6243 - val_loss: 1.3224 - val_acc: 0.3393 - val_mean_absolute_error: 0.5974\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 480ms/step - loss: 1.3619 - acc: 0.4293 - mean_absolute_error: 0.6548 - val_loss: 1.3376 - val_acc: 0.3036 - val_mean_absolute_error: 0.6185\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 469ms/step - loss: 1.3123 - acc: 0.4385 - mean_absolute_error: 0.6237 - val_loss: 1.3227 - val_acc: 0.3036 - val_mean_absolute_error: 0.6139\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 468ms/step - loss: 1.3403 - acc: 0.3594 - mean_absolute_error: 0.6429 - val_loss: 1.3217 - val_acc: 0.3036 - val_mean_absolute_error: 0.6201\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 1.3320 - acc: 0.2345 - mean_absolute_error: 0.6247 - val_loss: 1.3150 - val_acc: 0.3214 - val_mean_absolute_error: 0.6155\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 457ms/step - loss: 1.4149 - acc: 0.4068 - mean_absolute_error: 0.6338 - val_loss: 1.3033 - val_acc: 0.3036 - val_mean_absolute_error: 0.6172\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 1.3498 - acc: 0.4062 - mean_absolute_error: 0.6559 - val_loss: 1.3247 - val_acc: 0.3214 - val_mean_absolute_error: 0.6224\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 1.3091 - acc: 0.3892 - mean_absolute_error: 0.6502 - val_loss: 1.3176 - val_acc: 0.3036 - val_mean_absolute_error: 0.6155\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 479ms/step - loss: 1.3176 - acc: 0.3715 - mean_absolute_error: 0.6443 - val_loss: 1.3048 - val_acc: 0.3214 - val_mean_absolute_error: 0.6080\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 490ms/step - loss: 1.3062 - acc: 0.3906 - mean_absolute_error: 0.6240 - val_loss: 1.3063 - val_acc: 0.3393 - val_mean_absolute_error: 0.6073\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 476ms/step - loss: 1.2673 - acc: 0.3983 - mean_absolute_error: 0.6173 - val_loss: 1.3019 - val_acc: 0.3571 - val_mean_absolute_error: 0.6084\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 476ms/step - loss: 1.2460 - acc: 0.4068 - mean_absolute_error: 0.6155 - val_loss: 1.2938 - val_acc: 0.3036 - val_mean_absolute_error: 0.6005\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 474ms/step - loss: 1.2380 - acc: 0.4375 - mean_absolute_error: 0.6151 - val_loss: 1.2859 - val_acc: 0.3214 - val_mean_absolute_error: 0.5853\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 478ms/step - loss: 1.2975 - acc: 0.2875 - mean_absolute_error: 0.6311 - val_loss: 1.3186 - val_acc: 0.3393 - val_mean_absolute_error: 0.5886\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 479ms/step - loss: 1.2631 - acc: 0.4385 - mean_absolute_error: 0.6266 - val_loss: 1.2867 - val_acc: 0.3750 - val_mean_absolute_error: 0.5655\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 459ms/step - loss: 1.2668 - acc: 0.3281 - mean_absolute_error: 0.6086 - val_loss: 1.3030 - val_acc: 0.3571 - val_mean_absolute_error: 0.5536\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 448ms/step - loss: 1.2826 - acc: 0.3849 - mean_absolute_error: 0.5851 - val_loss: 1.2900 - val_acc: 0.3036 - val_mean_absolute_error: 0.5422\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 478ms/step - loss: 1.1975 - acc: 0.5091 - mean_absolute_error: 0.5799 - val_loss: 1.3319 - val_acc: 0.2857 - val_mean_absolute_error: 0.5326\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 474ms/step - loss: 1.2447 - acc: 0.3125 - mean_absolute_error: 0.5728 - val_loss: 1.3195 - val_acc: 0.3036 - val_mean_absolute_error: 0.5194\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 475ms/step - loss: 1.1722 - acc: 0.4293 - mean_absolute_error: 0.5515 - val_loss: 1.3587 - val_acc: 0.3393 - val_mean_absolute_error: 0.5139\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 1.2137 - acc: 0.3009 - mean_absolute_error: 0.5423 - val_loss: 1.3399 - val_acc: 0.2857 - val_mean_absolute_error: 0.5021\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 476ms/step - loss: 1.2018 - acc: 0.3906 - mean_absolute_error: 0.5304 - val_loss: 1.3502 - val_acc: 0.3036 - val_mean_absolute_error: 0.4954\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 477ms/step - loss: 1.1229 - acc: 0.4379 - mean_absolute_error: 0.5176 - val_loss: 1.4208 - val_acc: 0.3393 - val_mean_absolute_error: 0.4964\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 462ms/step - loss: 1.1710 - acc: 0.3009 - mean_absolute_error: 0.5248 - val_loss: 1.3997 - val_acc: 0.3571 - val_mean_absolute_error: 0.4876\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 466ms/step - loss: 1.1190 - acc: 0.5312 - mean_absolute_error: 0.5104 - val_loss: 1.4901 - val_acc: 0.3036 - val_mean_absolute_error: 0.4837\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 1.2775 - acc: 0.3630 - mean_absolute_error: 0.5368 - val_loss: 1.4683 - val_acc: 0.3571 - val_mean_absolute_error: 0.4769\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 461ms/step - loss: 1.1195 - acc: 0.3496 - mean_absolute_error: 0.4992 - val_loss: 1.5401 - val_acc: 0.3571 - val_mean_absolute_error: 0.4757\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 464ms/step - loss: 1.1588 - acc: 0.3281 - mean_absolute_error: 0.4995 - val_loss: 1.5466 - val_acc: 0.3036 - val_mean_absolute_error: 0.4703\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 473ms/step - loss: 1.1526 - acc: 0.2741 - mean_absolute_error: 0.4869 - val_loss: 1.5458 - val_acc: 0.3393 - val_mean_absolute_error: 0.4647\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 480ms/step - loss: 1.1025 - acc: 0.3496 - mean_absolute_error: 0.4693 - val_loss: 1.6531 - val_acc: 0.3571 - val_mean_absolute_error: 0.4627\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 1.0949 - acc: 0.2812 - mean_absolute_error: 0.4478 - val_loss: 1.7728 - val_acc: 0.3393 - val_mean_absolute_error: 0.4654\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 469ms/step - loss: 1.0334 - acc: 0.3051 - mean_absolute_error: 0.4403 - val_loss: 1.7513 - val_acc: 0.2857 - val_mean_absolute_error: 0.4636\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 460ms/step - loss: 1.1658 - acc: 0.4647 - mean_absolute_error: 0.4428 - val_loss: 1.7249 - val_acc: 0.3393 - val_mean_absolute_error: 0.4586\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 1.1100 - acc: 0.4375 - mean_absolute_error: 0.4395 - val_loss: 1.7332 - val_acc: 0.2857 - val_mean_absolute_error: 0.4589\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 489ms/step - loss: 1.0277 - acc: 0.4866 - mean_absolute_error: 0.4208 - val_loss: 1.6646 - val_acc: 0.3036 - val_mean_absolute_error: 0.4502\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 1.1103 - acc: 0.3934 - mean_absolute_error: 0.4517 - val_loss: 1.7198 - val_acc: 0.2321 - val_mean_absolute_error: 0.4509\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 467ms/step - loss: 1.0735 - acc: 0.4531 - mean_absolute_error: 0.4436 - val_loss: 1.7468 - val_acc: 0.2500 - val_mean_absolute_error: 0.4474\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 467ms/step - loss: 1.2223 - acc: 0.5091 - mean_absolute_error: 0.4661 - val_loss: 1.6765 - val_acc: 0.2143 - val_mean_absolute_error: 0.4451\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 479ms/step - loss: 0.9846 - acc: 0.4957 - mean_absolute_error: 0.4016 - val_loss: 1.6423 - val_acc: 0.2679 - val_mean_absolute_error: 0.4377\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 492ms/step - loss: 0.9965 - acc: 0.5000 - mean_absolute_error: 0.3992 - val_loss: 1.7419 - val_acc: 0.2500 - val_mean_absolute_error: 0.4360\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 471ms/step - loss: 1.0981 - acc: 0.4513 - mean_absolute_error: 0.4169 - val_loss: 1.7084 - val_acc: 0.2143 - val_mean_absolute_error: 0.4297\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 0.9337 - acc: 0.5085 - mean_absolute_error: 0.3615 - val_loss: 1.7471 - val_acc: 0.2321 - val_mean_absolute_error: 0.4240\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 459ms/step - loss: 1.0186 - acc: 0.6250 - mean_absolute_error: 0.3704 - val_loss: 1.7440 - val_acc: 0.1964 - val_mean_absolute_error: 0.4201\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 1.0174 - acc: 0.5396 - mean_absolute_error: 0.3585 - val_loss: 1.7398 - val_acc: 0.2857 - val_mean_absolute_error: 0.4113\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 468ms/step - loss: 0.8843 - acc: 0.6906 - mean_absolute_error: 0.3071 - val_loss: 1.7714 - val_acc: 0.2321 - val_mean_absolute_error: 0.3990\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 474ms/step - loss: 0.9247 - acc: 0.5938 - mean_absolute_error: 0.3372 - val_loss: 1.7471 - val_acc: 0.2679 - val_mean_absolute_error: 0.3863\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 488ms/step - loss: 0.7837 - acc: 0.6991 - mean_absolute_error: 0.2876 - val_loss: 1.6945 - val_acc: 0.3214 - val_mean_absolute_error: 0.3673\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 506ms/step - loss: 0.7776 - acc: 0.7479 - mean_absolute_error: 0.2926 - val_loss: 1.8316 - val_acc: 0.2500 - val_mean_absolute_error: 0.3677\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 459ms/step - loss: 0.8167 - acc: 0.7031 - mean_absolute_error: 0.2869 - val_loss: 1.8107 - val_acc: 0.3393 - val_mean_absolute_error: 0.3392\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 465ms/step - loss: 0.7223 - acc: 0.6194 - mean_absolute_error: 0.2453 - val_loss: 1.8938 - val_acc: 0.3929 - val_mean_absolute_error: 0.3286\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 466ms/step - loss: 0.8212 - acc: 0.7564 - mean_absolute_error: 0.2517 - val_loss: 1.8017 - val_acc: 0.3929 - val_mean_absolute_error: 0.3068\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 479ms/step - loss: 0.7512 - acc: 0.6719 - mean_absolute_error: 0.2327 - val_loss: 1.7602 - val_acc: 0.3929 - val_mean_absolute_error: 0.2917\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 456ms/step - loss: 1.0336 - acc: 0.6547 - mean_absolute_error: 0.2394 - val_loss: 1.8808 - val_acc: 0.3036 - val_mean_absolute_error: 0.2944\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.7642 - acc: 0.6681 - mean_absolute_error: 0.2340 - val_loss: 1.8253 - val_acc: 0.3036 - val_mean_absolute_error: 0.2871\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 0.7018 - acc: 0.7500 - mean_absolute_error: 0.1948 - val_loss: 1.7884 - val_acc: 0.3929 - val_mean_absolute_error: 0.2826\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 482ms/step - loss: 0.8475 - acc: 0.6681 - mean_absolute_error: 0.2267 - val_loss: 1.7541 - val_acc: 0.3571 - val_mean_absolute_error: 0.2803\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 486ms/step - loss: 0.7238 - acc: 0.7125 - mean_absolute_error: 0.2114 - val_loss: 1.6979 - val_acc: 0.3393 - val_mean_absolute_error: 0.2734\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 471ms/step - loss: 0.5034 - acc: 0.7969 - mean_absolute_error: 0.1703 - val_loss: 1.7980 - val_acc: 0.3036 - val_mean_absolute_error: 0.2764\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 478ms/step - loss: 0.6151 - acc: 0.7966 - mean_absolute_error: 0.1620 - val_loss: 1.6716 - val_acc: 0.4286 - val_mean_absolute_error: 0.2668\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 462ms/step - loss: 0.5760 - acc: 0.7747 - mean_absolute_error: 0.1610 - val_loss: 1.7168 - val_acc: 0.4464 - val_mean_absolute_error: 0.2646\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 453ms/step - loss: 0.5929 - acc: 0.8750 - mean_absolute_error: 0.1513 - val_loss: 1.6777 - val_acc: 0.4286 - val_mean_absolute_error: 0.2658\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 464ms/step - loss: 0.6277 - acc: 0.8715 - mean_absolute_error: 0.1520 - val_loss: 1.9128 - val_acc: 0.2857 - val_mean_absolute_error: 0.2688\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 443ms/step - loss: 0.5075 - acc: 0.8009 - mean_absolute_error: 0.1559 - val_loss: 2.0444 - val_acc: 0.3214 - val_mean_absolute_error: 0.2694\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 445ms/step - loss: 0.5008 - acc: 0.8125 - mean_absolute_error: 0.1459 - val_loss: 2.0824 - val_acc: 0.3750 - val_mean_absolute_error: 0.2636\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 454ms/step - loss: 0.5300 - acc: 0.7655 - mean_absolute_error: 0.1288 - val_loss: 2.1753 - val_acc: 0.3214 - val_mean_absolute_error: 0.2643\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 457ms/step - loss: 0.3383 - acc: 0.9160 - mean_absolute_error: 0.1185 - val_loss: 2.2262 - val_acc: 0.3214 - val_mean_absolute_error: 0.2642\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 474ms/step - loss: 0.3325 - acc: 0.8750 - mean_absolute_error: 0.1239 - val_loss: 2.2472 - val_acc: 0.3750 - val_mean_absolute_error: 0.2652\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 0.4118 - acc: 0.7966 - mean_absolute_error: 0.1324 - val_loss: 2.0695 - val_acc: 0.3750 - val_mean_absolute_error: 0.2593\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 0.2530 - acc: 0.9026 - mean_absolute_error: 0.1257 - val_loss: 2.0821 - val_acc: 0.3929 - val_mean_absolute_error: 0.2585\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 473ms/step - loss: 0.3669 - acc: 0.8750 - mean_absolute_error: 0.1468 - val_loss: 2.0577 - val_acc: 0.4107 - val_mean_absolute_error: 0.2598\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 487ms/step - loss: 0.3639 - acc: 0.8672 - mean_absolute_error: 0.1297 - val_loss: 2.1439 - val_acc: 0.3750 - val_mean_absolute_error: 0.2599\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 486ms/step - loss: 0.4882 - acc: 0.8185 - mean_absolute_error: 0.1531 - val_loss: 1.8781 - val_acc: 0.3929 - val_mean_absolute_error: 0.2561\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 0.3218 - acc: 0.9219 - mean_absolute_error: 0.1254 - val_loss: 1.8995 - val_acc: 0.3929 - val_mean_absolute_error: 0.2547\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 469ms/step - loss: 0.4736 - acc: 0.8009 - mean_absolute_error: 0.1487 - val_loss: 1.8738 - val_acc: 0.4464 - val_mean_absolute_error: 0.2568\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 0.2609 - acc: 0.8849 - mean_absolute_error: 0.1444 - val_loss: 2.0630 - val_acc: 0.4286 - val_mean_absolute_error: 0.2572\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 500ms/step - loss: 0.4672 - acc: 0.8438 - mean_absolute_error: 0.1430 - val_loss: 2.0458 - val_acc: 0.3929 - val_mean_absolute_error: 0.2560\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 464ms/step - loss: 0.2200 - acc: 0.9293 - mean_absolute_error: 0.1224 - val_loss: 2.1737 - val_acc: 0.4107 - val_mean_absolute_error: 0.2574\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 449ms/step - loss: 0.1394 - acc: 0.9647 - mean_absolute_error: 0.1014 - val_loss: 2.1955 - val_acc: 0.4107 - val_mean_absolute_error: 0.2569\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 444ms/step - loss: 0.2909 - acc: 0.9219 - mean_absolute_error: 0.1193 - val_loss: 2.3229 - val_acc: 0.3571 - val_mean_absolute_error: 0.2580\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 461ms/step - loss: 0.3940 - acc: 0.8849 - mean_absolute_error: 0.1259 - val_loss: 2.2699 - val_acc: 0.3929 - val_mean_absolute_error: 0.2583\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 471ms/step - loss: 0.3339 - acc: 0.8672 - mean_absolute_error: 0.1338 - val_loss: 2.2989 - val_acc: 0.3750 - val_mean_absolute_error: 0.2577\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 453ms/step - loss: 0.4502 - acc: 0.8281 - mean_absolute_error: 0.1192 - val_loss: 2.2489 - val_acc: 0.3750 - val_mean_absolute_error: 0.2551\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 453ms/step - loss: 0.2683 - acc: 0.9202 - mean_absolute_error: 0.1155 - val_loss: 2.3467 - val_acc: 0.3036 - val_mean_absolute_error: 0.2589\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 461ms/step - loss: 0.4651 - acc: 0.8362 - mean_absolute_error: 0.1218 - val_loss: 2.3845 - val_acc: 0.3571 - val_mean_absolute_error: 0.2581\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 438ms/step - loss: 0.2990 - acc: 0.9062 - mean_absolute_error: 0.1042 - val_loss: 2.5229 - val_acc: 0.3571 - val_mean_absolute_error: 0.2584\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 462ms/step - loss: 0.3873 - acc: 0.8672 - mean_absolute_error: 0.1286 - val_loss: 2.5471 - val_acc: 0.3214 - val_mean_absolute_error: 0.2588\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 471ms/step - loss: 0.3746 - acc: 0.8362 - mean_absolute_error: 0.1291 - val_loss: 2.4800 - val_acc: 0.3214 - val_mean_absolute_error: 0.2603\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.3685 - acc: 0.8750 - mean_absolute_error: 0.1231 - val_loss: 2.2602 - val_acc: 0.3750 - val_mean_absolute_error: 0.2557\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 424ms/step - loss: 0.2095 - acc: 0.9513 - mean_absolute_error: 0.1196 - val_loss: 2.1694 - val_acc: 0.3393 - val_mean_absolute_error: 0.2548\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.3401 - acc: 0.8538 - mean_absolute_error: 0.1388 - val_loss: 2.0260 - val_acc: 0.3929 - val_mean_absolute_error: 0.2545\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 466ms/step - loss: 0.1685 - acc: 0.9531 - mean_absolute_error: 0.0953 - val_loss: 2.0777 - val_acc: 0.3750 - val_mean_absolute_error: 0.2543\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 467ms/step - loss: 0.2891 - acc: 0.8983 - mean_absolute_error: 0.1118 - val_loss: 1.8840 - val_acc: 0.3929 - val_mean_absolute_error: 0.2529\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 448ms/step - loss: 0.2937 - acc: 0.8849 - mean_absolute_error: 0.1192 - val_loss: 2.0264 - val_acc: 0.3393 - val_mean_absolute_error: 0.2551\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 495ms/step - loss: 0.2893 - acc: 0.8438 - mean_absolute_error: 0.1119 - val_loss: 1.9265 - val_acc: 0.4107 - val_mean_absolute_error: 0.2535\n",
            "unfreeze all model ...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 3,755,716\n",
            "Trainable params: 3,733,828\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 10s 5s/step - loss: 0.2275 - acc: 0.9219 - mean_absolute_error: 0.1105 - val_loss: 0.1051 - val_acc: 0.9643 - val_mean_absolute_error: 0.0987\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 1s 513ms/step - loss: 0.1019 - acc: 0.9513 - mean_absolute_error: 0.1091 - val_loss: 0.0318 - val_acc: 1.0000 - val_mean_absolute_error: 0.1185\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 1s 330ms/step - loss: 0.0873 - acc: 0.9823 - mean_absolute_error: 0.1123 - val_loss: 0.0352 - val_acc: 0.9821 - val_mean_absolute_error: 0.1000\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 1s 416ms/step - loss: 0.1361 - acc: 0.9688 - mean_absolute_error: 0.1166 - val_loss: 0.0501 - val_acc: 1.0000 - val_mean_absolute_error: 0.1134\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.0614 - acc: 1.0000 - mean_absolute_error: 0.1183 - val_loss: 0.1229 - val_acc: 0.9464 - val_mean_absolute_error: 0.1174\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.0578 - acc: 0.9823 - mean_absolute_error: 0.0830 - val_loss: 0.0905 - val_acc: 0.9286 - val_mean_absolute_error: 0.1199\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 1s 410ms/step - loss: 0.0809 - acc: 0.9688 - mean_absolute_error: 0.0927 - val_loss: 0.0974 - val_acc: 0.9643 - val_mean_absolute_error: 0.1198\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.3796 - acc: 0.8581 - mean_absolute_error: 0.1377 - val_loss: 0.0978 - val_acc: 0.9286 - val_mean_absolute_error: 0.1170\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.1011 - acc: 0.9513 - mean_absolute_error: 0.0884 - val_loss: 0.1361 - val_acc: 0.9643 - val_mean_absolute_error: 0.1116\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 1s 408ms/step - loss: 0.0132 - acc: 1.0000 - mean_absolute_error: 0.0753 - val_loss: 0.0465 - val_acc: 0.9643 - val_mean_absolute_error: 0.1086\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.0047 - acc: 1.0000 - mean_absolute_error: 0.0574 - val_loss: 0.0427 - val_acc: 0.9643 - val_mean_absolute_error: 0.0928\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 0.0135 - acc: 1.0000 - mean_absolute_error: 0.0850 - val_loss: 0.0237 - val_acc: 1.0000 - val_mean_absolute_error: 0.0963\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 1s 459ms/step - loss: 0.1184 - acc: 0.9375 - mean_absolute_error: 0.0715 - val_loss: 0.0288 - val_acc: 0.9821 - val_mean_absolute_error: 0.0953\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 1s 505ms/step - loss: 0.1483 - acc: 0.9379 - mean_absolute_error: 0.0885 - val_loss: 0.0217 - val_acc: 1.0000 - val_mean_absolute_error: 0.0838\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 1s 530ms/step - loss: 0.0664 - acc: 0.9513 - mean_absolute_error: 0.0724 - val_loss: 0.0568 - val_acc: 0.9821 - val_mean_absolute_error: 0.0785\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.0206 - acc: 1.0000 - mean_absolute_error: 0.0620 - val_loss: 0.0321 - val_acc: 0.9821 - val_mean_absolute_error: 0.0768\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 1s 575ms/step - loss: 0.1982 - acc: 0.9689 - mean_absolute_error: 0.0814 - val_loss: 0.0279 - val_acc: 1.0000 - val_mean_absolute_error: 0.0705\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 1s 527ms/step - loss: 0.0244 - acc: 0.9823 - mean_absolute_error: 0.0593 - val_loss: 0.0311 - val_acc: 0.9821 - val_mean_absolute_error: 0.0701\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 1s 585ms/step - loss: 0.0113 - acc: 1.0000 - mean_absolute_error: 0.0559 - val_loss: 0.0813 - val_acc: 0.9643 - val_mean_absolute_error: 0.0710\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 1s 548ms/step - loss: 0.0077 - acc: 1.0000 - mean_absolute_error: 0.0419 - val_loss: 0.0654 - val_acc: 0.9464 - val_mean_absolute_error: 0.0711\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 1s 541ms/step - loss: 0.0193 - acc: 1.0000 - mean_absolute_error: 0.0584 - val_loss: 0.0967 - val_acc: 0.9821 - val_mean_absolute_error: 0.0723\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 1s 573ms/step - loss: 0.0349 - acc: 0.9844 - mean_absolute_error: 0.0649 - val_loss: 0.1237 - val_acc: 0.9286 - val_mean_absolute_error: 0.0710\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 1s 551ms/step - loss: 0.0020 - acc: 1.0000 - mean_absolute_error: 0.0497 - val_loss: 0.0681 - val_acc: 0.9464 - val_mean_absolute_error: 0.0683\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 1s 506ms/step - loss: 0.0155 - acc: 1.0000 - mean_absolute_error: 0.0649 - val_loss: 0.0689 - val_acc: 0.9643 - val_mean_absolute_error: 0.0705\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 1s 551ms/step - loss: 0.0104 - acc: 1.0000 - mean_absolute_error: 0.0620 - val_loss: 0.0818 - val_acc: 0.9643 - val_mean_absolute_error: 0.0731\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 1s 528ms/step - loss: 0.0272 - acc: 0.9823 - mean_absolute_error: 0.0657 - val_loss: 0.0981 - val_acc: 0.9643 - val_mean_absolute_error: 0.0685\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 1s 528ms/step - loss: 0.0174 - acc: 1.0000 - mean_absolute_error: 0.0518 - val_loss: 0.0411 - val_acc: 0.9821 - val_mean_absolute_error: 0.0679\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 1s 533ms/step - loss: 0.0374 - acc: 0.9844 - mean_absolute_error: 0.0536 - val_loss: 0.0542 - val_acc: 0.9643 - val_mean_absolute_error: 0.0700\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 1s 557ms/step - loss: 0.0117 - acc: 1.0000 - mean_absolute_error: 0.0487 - val_loss: 0.0401 - val_acc: 0.9821 - val_mean_absolute_error: 0.0730\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 1s 549ms/step - loss: 0.0013 - acc: 1.0000 - mean_absolute_error: 0.0661 - val_loss: 0.0515 - val_acc: 0.9821 - val_mean_absolute_error: 0.0700\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 1s 553ms/step - loss: 0.0018 - acc: 1.0000 - mean_absolute_error: 0.0505 - val_loss: 0.0222 - val_acc: 0.9821 - val_mean_absolute_error: 0.0690\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 0.0308 - acc: 0.9689 - mean_absolute_error: 0.0974 - val_loss: 0.0249 - val_acc: 0.9821 - val_mean_absolute_error: 0.0661\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 1s 569ms/step - loss: 4.0300e-04 - acc: 1.0000 - mean_absolute_error: 0.0543 - val_loss: 0.0276 - val_acc: 0.9821 - val_mean_absolute_error: 0.0658\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 1s 513ms/step - loss: 0.0653 - acc: 0.9844 - mean_absolute_error: 0.0519 - val_loss: 0.0080 - val_acc: 1.0000 - val_mean_absolute_error: 0.0643\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 1s 497ms/step - loss: 0.0085 - acc: 1.0000 - mean_absolute_error: 0.0578 - val_loss: 0.0103 - val_acc: 1.0000 - val_mean_absolute_error: 0.0677\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 1s 515ms/step - loss: 0.0109 - acc: 1.0000 - mean_absolute_error: 0.0516 - val_loss: 0.0057 - val_acc: 1.0000 - val_mean_absolute_error: 0.0630\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 0.0023 - acc: 1.0000 - mean_absolute_error: 0.0468 - val_loss: 0.0030 - val_acc: 1.0000 - val_mean_absolute_error: 0.0601\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 1s 509ms/step - loss: 8.0293e-04 - acc: 1.0000 - mean_absolute_error: 0.0266 - val_loss: 0.0032 - val_acc: 1.0000 - val_mean_absolute_error: 0.0583\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 1s 544ms/step - loss: 0.0011 - acc: 1.0000 - mean_absolute_error: 0.0509 - val_loss: 0.0029 - val_acc: 1.0000 - val_mean_absolute_error: 0.0554\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 1s 577ms/step - loss: 0.0014 - acc: 1.0000 - mean_absolute_error: 0.0494 - val_loss: 0.0023 - val_acc: 1.0000 - val_mean_absolute_error: 0.0594\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 1s 509ms/step - loss: 3.4113e-04 - acc: 1.0000 - mean_absolute_error: 0.0460 - val_loss: 0.0013 - val_acc: 1.0000 - val_mean_absolute_error: 0.0577\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 1s 552ms/step - loss: 0.0064 - acc: 1.0000 - mean_absolute_error: 0.0449 - val_loss: 0.0137 - val_acc: 1.0000 - val_mean_absolute_error: 0.0576\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.0014 - acc: 1.0000 - mean_absolute_error: 0.0432 - val_loss: 0.0141 - val_acc: 1.0000 - val_mean_absolute_error: 0.0527\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 1s 534ms/step - loss: 0.0030 - acc: 1.0000 - mean_absolute_error: 0.0400 - val_loss: 0.0039 - val_acc: 1.0000 - val_mean_absolute_error: 0.0464\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 1s 538ms/step - loss: 0.0182 - acc: 1.0000 - mean_absolute_error: 0.0593 - val_loss: 0.0090 - val_acc: 1.0000 - val_mean_absolute_error: 0.0580\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 0.0027 - acc: 1.0000 - mean_absolute_error: 0.0428 - val_loss: 0.0035 - val_acc: 1.0000 - val_mean_absolute_error: 0.0609\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 1s 568ms/step - loss: 0.0259 - acc: 0.9689 - mean_absolute_error: 0.0540 - val_loss: 0.0026 - val_acc: 1.0000 - val_mean_absolute_error: 0.0611\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 1s 544ms/step - loss: 8.4868e-04 - acc: 1.0000 - mean_absolute_error: 0.0561 - val_loss: 0.0019 - val_acc: 1.0000 - val_mean_absolute_error: 0.0625\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 1s 528ms/step - loss: 0.0011 - acc: 1.0000 - mean_absolute_error: 0.0583 - val_loss: 0.0283 - val_acc: 0.9821 - val_mean_absolute_error: 0.0606\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 1s 541ms/step - loss: 0.0282 - acc: 0.9647 - mean_absolute_error: 0.0550 - val_loss: 0.0029 - val_acc: 1.0000 - val_mean_absolute_error: 0.0661\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 2.9549e-04 - acc: 1.0000 - mean_absolute_error: 0.0626 - val_loss: 0.0098 - val_acc: 1.0000 - val_mean_absolute_error: 0.0653\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 1s 564ms/step - loss: 0.0039 - acc: 1.0000 - mean_absolute_error: 0.0611 - val_loss: 0.0037 - val_acc: 1.0000 - val_mean_absolute_error: 0.0661\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 1s 504ms/step - loss: 4.8103e-04 - acc: 1.0000 - mean_absolute_error: 0.0573 - val_loss: 0.0087 - val_acc: 1.0000 - val_mean_absolute_error: 0.0614\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 1s 577ms/step - loss: 0.0709 - acc: 0.9823 - mean_absolute_error: 0.0705 - val_loss: 0.0029 - val_acc: 1.0000 - val_mean_absolute_error: 0.0611\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 1s 549ms/step - loss: 0.0015 - acc: 1.0000 - mean_absolute_error: 0.0460 - val_loss: 0.0143 - val_acc: 0.9821 - val_mean_absolute_error: 0.0650\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 1s 520ms/step - loss: 0.0023 - acc: 1.0000 - mean_absolute_error: 0.0427 - val_loss: 0.0126 - val_acc: 1.0000 - val_mean_absolute_error: 0.0608\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 1s 567ms/step - loss: 4.2524e-04 - acc: 1.0000 - mean_absolute_error: 0.0437 - val_loss: 0.0024 - val_acc: 1.0000 - val_mean_absolute_error: 0.0631\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 1s 554ms/step - loss: 0.0143 - acc: 1.0000 - mean_absolute_error: 0.0641 - val_loss: 0.0153 - val_acc: 0.9821 - val_mean_absolute_error: 0.0625\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 1s 546ms/step - loss: 2.6761e-04 - acc: 1.0000 - mean_absolute_error: 0.0410 - val_loss: 0.0024 - val_acc: 1.0000 - val_mean_absolute_error: 0.0616\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 1s 468ms/step - loss: 0.0035 - acc: 1.0000 - mean_absolute_error: 0.0430 - val_loss: 0.0111 - val_acc: 1.0000 - val_mean_absolute_error: 0.0666\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 1s 557ms/step - loss: 0.0348 - acc: 0.9844 - mean_absolute_error: 0.0524 - val_loss: 0.0041 - val_acc: 1.0000 - val_mean_absolute_error: 0.0651\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 1s 520ms/step - loss: 0.0057 - acc: 1.0000 - mean_absolute_error: 0.0737 - val_loss: 0.0089 - val_acc: 1.0000 - val_mean_absolute_error: 0.0676\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 1s 511ms/step - loss: 0.0042 - acc: 1.0000 - mean_absolute_error: 0.0447 - val_loss: 0.0029 - val_acc: 1.0000 - val_mean_absolute_error: 0.0730\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 7.0670e-04 - acc: 1.0000 - mean_absolute_error: 0.0524 - val_loss: 0.0245 - val_acc: 0.9821 - val_mean_absolute_error: 0.0663\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 1s 567ms/step - loss: 0.0078 - acc: 1.0000 - mean_absolute_error: 0.0742 - val_loss: 0.0025 - val_acc: 1.0000 - val_mean_absolute_error: 0.0623\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 1s 529ms/step - loss: 0.0049 - acc: 1.0000 - mean_absolute_error: 0.0531 - val_loss: 0.0025 - val_acc: 1.0000 - val_mean_absolute_error: 0.0614\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.0016 - acc: 1.0000 - mean_absolute_error: 0.0297 - val_loss: 0.0060 - val_acc: 1.0000 - val_mean_absolute_error: 0.0562\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 1s 525ms/step - loss: 0.0021 - acc: 1.0000 - mean_absolute_error: 0.0553 - val_loss: 0.0030 - val_acc: 1.0000 - val_mean_absolute_error: 0.0625\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 1s 469ms/step - loss: 0.0493 - acc: 0.9689 - mean_absolute_error: 0.0498 - val_loss: 0.0027 - val_acc: 1.0000 - val_mean_absolute_error: 0.0557\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 1s 565ms/step - loss: 0.0042 - acc: 1.0000 - mean_absolute_error: 0.0310 - val_loss: 0.0034 - val_acc: 1.0000 - val_mean_absolute_error: 0.0612\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 1s 519ms/step - loss: 0.0041 - acc: 1.0000 - mean_absolute_error: 0.0312 - val_loss: 0.0034 - val_acc: 1.0000 - val_mean_absolute_error: 0.0588\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 1s 538ms/step - loss: 0.0353 - acc: 0.9689 - mean_absolute_error: 0.0305 - val_loss: 0.0188 - val_acc: 0.9821 - val_mean_absolute_error: 0.0602\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 1s 561ms/step - loss: 0.0428 - acc: 0.9688 - mean_absolute_error: 0.0511 - val_loss: 0.0108 - val_acc: 1.0000 - val_mean_absolute_error: 0.0537\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 1s 515ms/step - loss: 0.0123 - acc: 1.0000 - mean_absolute_error: 0.0437 - val_loss: 0.0037 - val_acc: 1.0000 - val_mean_absolute_error: 0.0467\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 1s 446ms/step - loss: 0.0012 - acc: 1.0000 - mean_absolute_error: 0.0444 - val_loss: 0.0084 - val_acc: 1.0000 - val_mean_absolute_error: 0.0516\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 1s 501ms/step - loss: 0.0019 - acc: 1.0000 - mean_absolute_error: 0.0468 - val_loss: 0.0098 - val_acc: 1.0000 - val_mean_absolute_error: 0.0440\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 1s 502ms/step - loss: 0.0013 - acc: 1.0000 - mean_absolute_error: 0.0378 - val_loss: 0.0302 - val_acc: 0.9821 - val_mean_absolute_error: 0.0430\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 1s 551ms/step - loss: 0.0080 - acc: 1.0000 - mean_absolute_error: 0.0475 - val_loss: 0.0094 - val_acc: 1.0000 - val_mean_absolute_error: 0.0461\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 1s 561ms/step - loss: 2.6887e-04 - acc: 1.0000 - mean_absolute_error: 0.0272 - val_loss: 0.0481 - val_acc: 0.9821 - val_mean_absolute_error: 0.0512\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 1s 559ms/step - loss: 4.0292e-04 - acc: 1.0000 - mean_absolute_error: 0.0410 - val_loss: 0.0325 - val_acc: 0.9821 - val_mean_absolute_error: 0.0485\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 1.5096e-04 - acc: 1.0000 - mean_absolute_error: 0.0219 - val_loss: 0.0147 - val_acc: 1.0000 - val_mean_absolute_error: 0.0416\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 0.0013 - acc: 1.0000 - mean_absolute_error: 0.0319 - val_loss: 0.0024 - val_acc: 1.0000 - val_mean_absolute_error: 0.0442\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 1s 490ms/step - loss: 0.0010 - acc: 1.0000 - mean_absolute_error: 0.0376 - val_loss: 0.0376 - val_acc: 0.9643 - val_mean_absolute_error: 0.0439\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 1s 562ms/step - loss: 1.4201e-04 - acc: 1.0000 - mean_absolute_error: 0.0245 - val_loss: 0.0079 - val_acc: 1.0000 - val_mean_absolute_error: 0.0458\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 1s 509ms/step - loss: 0.0071 - acc: 1.0000 - mean_absolute_error: 0.0391 - val_loss: 0.0258 - val_acc: 0.9821 - val_mean_absolute_error: 0.0502\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 1s 534ms/step - loss: 0.1536 - acc: 0.9689 - mean_absolute_error: 0.0531 - val_loss: 0.0041 - val_acc: 1.0000 - val_mean_absolute_error: 0.0443\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 1s 491ms/step - loss: 0.0018 - acc: 1.0000 - mean_absolute_error: 0.0374 - val_loss: 0.0118 - val_acc: 1.0000 - val_mean_absolute_error: 0.0381\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 1s 560ms/step - loss: 0.0012 - acc: 1.0000 - mean_absolute_error: 0.0427 - val_loss: 0.0031 - val_acc: 1.0000 - val_mean_absolute_error: 0.0383\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 1s 505ms/step - loss: 0.0019 - acc: 1.0000 - mean_absolute_error: 0.0426 - val_loss: 0.0099 - val_acc: 1.0000 - val_mean_absolute_error: 0.0439\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 1s 494ms/step - loss: 8.8514e-05 - acc: 1.0000 - mean_absolute_error: 0.0288 - val_loss: 0.0029 - val_acc: 1.0000 - val_mean_absolute_error: 0.0376\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 1s 512ms/step - loss: 7.2499e-04 - acc: 1.0000 - mean_absolute_error: 0.0208 - val_loss: 0.0039 - val_acc: 1.0000 - val_mean_absolute_error: 0.0329\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 1s 511ms/step - loss: 2.4302e-04 - acc: 1.0000 - mean_absolute_error: 0.0208 - val_loss: 0.0079 - val_acc: 1.0000 - val_mean_absolute_error: 0.0353\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 1s 513ms/step - loss: 2.0611e-04 - acc: 1.0000 - mean_absolute_error: 0.0258 - val_loss: 0.0059 - val_acc: 1.0000 - val_mean_absolute_error: 0.0403\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 1s 509ms/step - loss: 0.0029 - acc: 1.0000 - mean_absolute_error: 0.0283 - val_loss: 0.0013 - val_acc: 1.0000 - val_mean_absolute_error: 0.0369\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 1s 538ms/step - loss: 0.0102 - acc: 1.0000 - mean_absolute_error: 0.0574 - val_loss: 0.0099 - val_acc: 1.0000 - val_mean_absolute_error: 0.0347\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 1s 518ms/step - loss: 0.0012 - acc: 1.0000 - mean_absolute_error: 0.0276 - val_loss: 0.0031 - val_acc: 1.0000 - val_mean_absolute_error: 0.0375\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 1s 472ms/step - loss: 0.0013 - acc: 1.0000 - mean_absolute_error: 0.0292 - val_loss: 0.0270 - val_acc: 0.9821 - val_mean_absolute_error: 0.0363\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 1s 516ms/step - loss: 2.9223e-04 - acc: 1.0000 - mean_absolute_error: 0.0285 - val_loss: 0.0058 - val_acc: 1.0000 - val_mean_absolute_error: 0.0355\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 1s 529ms/step - loss: 8.9466e-04 - acc: 1.0000 - mean_absolute_error: 0.0337 - val_loss: 0.0054 - val_acc: 1.0000 - val_mean_absolute_error: 0.0384\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 7.9331e-04 - acc: 1.0000 - mean_absolute_error: 0.0207 - val_loss: 0.0025 - val_acc: 1.0000 - val_mean_absolute_error: 0.0348\n",
            "end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bBwTWkz7lyUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}